{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYnJJYUxbdua"
   },
   "source": [
    "# SteganoGAN in Keras\n",
    "This notebook contains code attempting to reimplement SteganoGAN in Keras, for the purpose of better understanding (and scrutinizing) it.\n",
    "\n",
    "*Based on https://github.com/DAI-Lab/SteganoGAN/tree/master/steganogan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTRQl5_KUxUA"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QbnEM8Oubduh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 23:35:38.697045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from callbacks import SaveImages\n",
    "\n",
    "from resnet_steganogan_gp import ResnetSteganoGAN\n",
    "from models import ResidualEncoder, BasicDecoder, Critic\n",
    "from dataset_utils import create_message_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE_DEPTH = 6\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "MODEL_PATH = 'ResnetSteganoGAN.weights.h5'\n",
    "LOGS_PATH = 'ResnetSteganoGAN.csv'\n",
    "CALLBACK_IMAGES_PATH = 'images/callback'\n",
    "CALLBACK_IMAGES_OUTPUT_PATH = 'epoch_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model for future train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResidualEncoder(MESSAGE_DEPTH)\n",
    "decoder = BasicDecoder(MESSAGE_DEPTH)\n",
    "critic = Critic()\n",
    "\n",
    "encoder.build(input_shape=[(None, None, None, IMAGE_CHANNELS), (None, None, None, MESSAGE_DEPTH)])\n",
    "decoder.build(input_shape=(None, None, None, IMAGE_CHANNELS))\n",
    "critic.build(input_shape=(None, None, None, IMAGE_CHANNELS))\n",
    "\n",
    "resnetSteganoGAN = ResnetSteganoGAN(\n",
    "  encoder=encoder,\n",
    "  decoder=decoder,\n",
    "  critic=critic,\n",
    "  data_depth=MESSAGE_DEPTH\n",
    ")\n",
    "\n",
    "resnetSteganoGAN.build(input_shape=[(None, None, None, IMAGE_CHANNELS), (None, None, None, MESSAGE_DEPTH)])\n",
    "\n",
    "if MODEL_PATH is not None and os.path.exists(MODEL_PATH):\n",
    "  resnetSteganoGAN.load_weights(MODEL_PATH)\n",
    "  print(f'Model loaded from {MODEL_PATH}')\n",
    "\n",
    "resnetSteganoGAN.compile(\n",
    "  encoder_optimizer  = Adam(learning_rate=1e-4),\n",
    "  decoder_optimizer  = Adam(learning_rate=1e-4),\n",
    "  critic_optimizer   = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9),\n",
    "  similarity_loss_fn = MeanSquaredError(),\n",
    "  decoder_loss_fn    = BinaryCrossentropy(from_logits=False) # false means that data to compare is in [0, 1]\n",
    ")\n",
    "\n",
    "# resnetSteganoGAN.summary()\n",
    "# resnetSteganoGAN.encoder.summary()\n",
    "# resnetSteganoGAN.decoder.summary()\n",
    "# resnetSteganoGAN.critic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download div2k dataset and complete it with random message dataset of {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load DIV2K dataset\n",
    "ds_div2k = tfds.load('div2k', shuffle_files=True)\n",
    "\n",
    "# Extract and preprocess high-resolution images\n",
    "def preprocess_hr(image):\n",
    "    image = tf.image.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))  # Resize to target shape\n",
    "    image = tf.cast(image, tf.float32)      # Convert to float\n",
    "    image = (image / 127.5) - 1.0  # Normalize to [-1, 1]\n",
    "    return image\n",
    "\n",
    "train_image_ds = ds_div2k['train'].map(lambda x: preprocess_hr(x['hr']), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_image_ds = ds_div2k['validation'].map(lambda x: preprocess_hr(x['hr']), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch datasets\n",
    "train_image_ds = train_image_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_image_ds = val_image_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Create message datasets\n",
    "train_message_ds = create_message_dataset(len(train_image_ds) * BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH).batch(BATCH_SIZE)\n",
    "val_message_ds = create_message_dataset(len(val_image_ds) * BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH).batch(BATCH_SIZE)\n",
    "\n",
    "# Combine image and message datasets\n",
    "train_ds = tf.data.Dataset.zip((train_image_ds, train_message_ds))\n",
    "val_ds = tf.data.Dataset.zip((val_image_ds, val_message_ds))\n",
    "\n",
    "# # Example usage\n",
    "# for images, messages in train_ds.take(1):\n",
    "#     print(\"Image batch shape:\", images.shape)\n",
    "#     print(\"Message batch shape:\", messages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - critic_loss: 330.9911 - decoder_accuracy: 0.5001 - decoder_loss: 0.7385 - encoder_decoder_total_loss: 16821.7793 - psnr: -41.7834 - realism_loss: -0.0104 - similarity_loss: 16821.0488 - ssim: inf - val_critic_loss: -1.5182 - val_decoder_accuracy: 0.5002 - val_decoder_loss: 0.6942 - val_encoder_decoder_total_loss: 16539.3887 - val_psnr: -41.4581 - val_realism_loss: -0.0046 - val_similarity_loss: 16538.6992 - val_ssim: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14d3838f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetSteganoGAN.fit(train_ds, epochs=1, validation_data=val_ds, initial_epoch=0, callbacks=[\n",
    "  CSVLogger(LOGS_PATH, append=True),\n",
    "  ModelCheckpoint(MODEL_PATH, monitor='encoder_decoder_total_loss', mode='min', save_weights_only=True),\n",
    "  SaveImages(MESSAGE_DEPTH, IMAGE_SHAPE, CALLBACK_IMAGES_PATH, CALLBACK_IMAGES_OUTPUT_PATH)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - critic_loss: -1.4506 - decoder_accuracy: 0.5000 - decoder_loss: 0.6943 - encoder_decoder_total_loss: 15586.0791 - psnr: -41.1314 - realism_loss: -0.0046 - similarity_loss: 15585.3887 - ssim: inf\n",
      "encoder_decoder_total_loss: 16539.38671875\n",
      "critic_loss: -1.5171455144882202\n",
      "similarity_loss: 16538.6953125\n",
      "decoder_loss: 0.6942342519760132\n",
      "decoder_accuracy: 0.5002461671829224\n",
      "realism_loss: -0.004601673223078251\n",
      "psnr: -41.45809555053711\n",
      "ssim: inf\n"
     ]
    }
   ],
   "source": [
    "evaluated_metrics = resnetSteganoGAN.evaluate(val_ds)\n",
    "\n",
    "metrics_names = [\n",
    "  'encoder_decoder_total_loss',\n",
    "  'critic_loss',\n",
    "  'similarity_loss',\n",
    "  'decoder_loss',\n",
    "  'decoder_accuracy',\n",
    "  'realism_loss',\n",
    "  'psnr',\n",
    "  'ssim'\n",
    "]\n",
    "\n",
    "for key, value in zip(metrics_names, evaluated_metrics):\n",
    "  print(f'{key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "steganogan_keras.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jnickg/steganet/blob/main/steganogan_keras.ipynb",
     "timestamp": 1710610773710
    }
   ]
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
